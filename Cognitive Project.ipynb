{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Lab Assignment 01 - Notebook.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Io5obvgGaBFH"},"source":["# TBANLT 585 - Lab Assignment 01 - Introduction to Machine Learning Using Python!\n","In this lab you will work through a complete machine learning project, step by step, from start to finish. By the time you have completed this lab, you will have achieved all of the following learning objectives:\n","### Learning Objectives\n","* Train, test, and compare several machine learning models that solve an important, real-world problem.\n","* Use Python to load and familiarize yourself with a large, real-world dataset.\n","* Create visualizations to gain insights into variables and inter-variable relationships.\n","* Prepare data so that they can be used as input into machine learning algorithms.\n","* Gain experience working with Python and Google Colaboratory notebooks.\n","\n","### Import Libraries\n","Run the code cell below to import all of the libraries that we'll need for this lab assignment."]},{"cell_type":"code","metadata":{"trusted":true,"id":"JiqFCgY4aBFT"},"source":["#import all of the libraries that we'll need for this lab\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import sklearn.metrics as sklm\n","import seaborn as sns\n","import warnings\n","from scipy.stats import norm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hTNxJZ_aBFW"},"source":["### Load Data\n","All machine learning projects require data, so we'll begin by uploading our data file for this lab, and then loading our data into a *pandas dataframe*. If you are unfamiliar with pandas, then please read the following Wikipedia article: <a href=\"https://en.wikipedia.org/wiki/Pandas_(software)\">https://en.wikipedia.org/wiki/Pandas_(software)</a>\n","\n","Before continuing, be sure to upload the `Lab Assignment 01 - Data.csv` file into your Google Colab notebook's session storage by clicking on the *Files* (folder) icon in the upper-left corner of your screen, and then clicking on the *Upload to session storage* button.\n","\n","#### Dataset Overview\n","The data for this lab are derived from the *Pima Indians Diabetes dataset*, which was published by the National Institute of Diabetes and Digestive and Kidney Diseases. The dataset contains information about women who are members of the Pima people -- a group of Native Americans living in an area consisting of what is now central and southern Arizona. The dataset contains several diagnostic measurements for each woman, including whether each woman has diabetes.\n","#### Dataset Variables\n","The dataset contains the following variables:\n","* <u>Pregnancies</u>: The number of times a woman has been pregnant\n","* <u>Plasma_Glucose</u>: A measurement of a woman's plasma glucose concentration\n","* <u>Diastolic_Blood_Pressure</u>: A woman's diastolic blood pressure (in mm Hg)\n","* <u>Triceps_Thickness</u>: The thickness of a woman's triceps skin fold (in mm)\n","* <u>Serum_Insulin</u>: A woman's serum insulin level (in mu U/ml)\n","* <u>BMI</u>: A woman's body mass index (weight in kg/(height in m)<sup>2</sup>)\n","* <u>Diabetes_Pedigree</u>: The likelihood of a woman having diabetes based on her family history\n","* <u>Age</u>: A woman's age (in years)\n","* <u>Has_Diabetes</u>: Whether a woman has diabetes (0 = does not have diabetes, 1 = has diabetes)\n","\n","Run the code cell below to load the diabetes data into a pandas dataframe."]},{"cell_type":"code","metadata":{"trusted":true,"id":"kaxsbSBtaBFX"},"source":["#Load the diabetes data into a pandas dataframe named \"df\".\n","#\"Patient_ID\" is an attribute in the dataset whose values uniquely identify a woman. The \"index_col\" parameter\n","#tells Pandas to use Patient_ID as the index column in the dataframe. The index column serves the same purpose\n","#in a dataframe as a primary key in a relational database table.\n","df = pd.read_csv('Lab Assignment 01 - Data.csv', index_col='Patient_ID')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AbIM6kOjaBFY"},"source":["### Preview the Data\n","Read about the pandas dataframe `head` function [on this webpage](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html).\n","#### Task 01:\n","Write a line of code in the cell below that will display the first 10 rows of data in the `df` dataframe.\n","#### Question 01:\n","What is the age of the 10th woman in the dataset (i.e., the woman with `Patient_ID` = 10)?"]},{"cell_type":"code","metadata":{"trusted":true,"id":"rBf_EX1GaBFY"},"source":["#display the first 10 rows of data in the dataframe\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yIROWANiaBFZ"},"source":["### Generate Descriptive Statistics\n","Read about the pandas dataframe `describe` function [on this webpage](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html).\n","#### Task 02:\n","Write a line of code in the cell below that will display descriptive statistics for all of the variables in the `df` dataframe.\n","#### Question 02:\n","What is the standard deviation of the `BMI` variable? Report three decimals of precision (e.g., 5.678)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"oXI-R7ctaBFZ"},"source":["#display descriptive statistics for all of the variables in the dataframe\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPKe3jroaBFa"},"source":["Notice that the dataset contains information about 15,000 women. This is not exactly \"big data\", but it certainly is not a small dataset either!\n","### Visualize the Distribution of Each Variable\n","#### Task 03:\n","Run the code cell below to visualize how the data for each variable in the dataset are distributed. I used nested `for` loops to create these figures because I'm lazy -- otherwise I would need to write instructions to create each of the nine figures individually!\n","#### Question 03:\n","How would you characterize the distribution of the `age` variable? Is it normally distributed, left skewed (i.e., negatively skewed), or right skewed (i.e., positively skewed)?\n","\n","If you're unsure, please read [this article about skewness](https://en.wikipedia.org/wiki/Skewness)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"5McreznCaBFb"},"source":["#generate kernel density estimate (KDE) plots for all nine variables in the dataset\n","rows, cols = 3, 3\n","df_col_index = 0\n","fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n","for row in range(rows):\n","  for col in range(cols):\n","    sns.kdeplot(df[df.columns[df_col_index]], ax=ax[row, col], fill=True, lw=2)\n","    df_col_index += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vbmXKxyQaBFc"},"source":["### Compare Distributions for Diabetic vs. Non-Diabetic Women\n","Since we're interested in creating a machine learning model that can predict whether or not a woman has diabetes, let's take a look at how the distributions of our predictor variables vary according to different values of the `Has_Diabetes` variable.\n","#### Task 04:\n","Run the code cell below to create box plots that show how the values of each predictor variable differ according to whether a woman has diabetes or not.\n","#### Question 04:\n","What can you conclude about the relationship between the number of times a woman has been pregnant and her likelihood of having diabetes?\n","\n","If you're unsure, please read [this article about box plots](https://en.wikipedia.org/wiki/Box_plot)"]},{"cell_type":"code","metadata":{"trusted":true,"id":"qx-CXeqiaBFd"},"source":["#generate box plots that show how the distribution of each predictor variable differs\n","#according to whether a woman has diabetes or not\n","rows, cols = 2, 4\n","df_col_index = 0\n","fig, ax = plt.subplots(rows, cols, figsize=(18,9))\n","for row in range(rows):\n","  for col in range(cols):\n","    sns.boxplot(x='Has_Diabetes', y=df.columns[df_col_index], data=df, ax=ax[row, col])\n","    df_col_index += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I6ggr-DEaBFe"},"source":["### Correlations Among Variables\n","Examining a correlation matrix is a quick and useful way of familiarizing yourself with the relationships among your variables. Read about the pandas dataframe `corr` function [on this webpage](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html).\n","#### Task 05:\n","Write a line of code in the cell below that will display a (pearson) correlation matrix for all of the variables in the dataset.\n","#### Question 05:\n","Which three variables are the most strongly correlated with whether or not a woman has diabetes?\n","\n","If you're unsure or if you need a reminder about how to interpret correlation coefficients, please read [this article about correlations](https://en.wikipedia.org/wiki/Correlation_and_dependence)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"8h3cMSpJaBFe"},"source":["#display a correlation matrix for all of the variables in the dataset\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T_-ojEnVaBFf"},"source":["### Correlation Matrix Heatmap\n","A correlation matrix heatmap uses colors of varying intensities to visually depict the strength and direction of the relationships among a set of variables.\n","\n","Run the code cell below to draw a correlation matrix heatmap for our diabetes dataset.\n","* Note that only one of the correlations is negative; i.e., with only one exception, each variable is positively related to all of the other variables.\n","* Note also that most of the relationships are quite weak (i.e., most of the correlations are near zero)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"9eBStPWzaBFf"},"source":["#draw a correlation matrix heatmap\n","fig, ax = plt.subplots(figsize=(10,7))\n","sns.heatmap(df.corr(), annot=True, fmt='.3f', vmin=-1, vmax=1, center=0, cmap='coolwarm', ax=ax)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GpBl1WRbaBFg"},"source":["## Prepare Data\n","Now that we're familiar with our dataset, we can work on getting the data ready to be used for training and testing our machine learning models. This is already a relatively \"clean\" dataset, so we won't need to worry about issues such as missing values, recoding variables, etc. Instead, we'll just need to transform a few skewed variables, rescale the predictor variables, and then split the data into training and testing sets.\n","### Transform Skewed Variables\n","Earlier in this lab we looked at distribution (KDE) plots for all of the variables in the dataset. These plots revealed that several of the variables have skewed distributions. Based on the direction of the skew, we can apply a **natural log transformation** to these variables in order to make their relationships with other variables more linear. Note that if the variables were skewed in the opposite direction, then we could apply an **exponential transformation** in order to make their relationships with other variables more linear.\n","\n","***Why should we transform skewed variables?*** Because many machine learning algorithms work best when the relationships among the variables are as linear as possible!\n","\n","Applying a transformation to a skewed variable will rarely make its distribution perfectly normal, but it can help to make the distribution *more normal*, and this is often sufficient to improve the performance of a machine learning model.\n","\n","Run the code cell below to apply a natural log transformation to the `Pregnancies`, `Serum_Insulin`, `BMI`, `Diabetes_Pedigree`, and `Age` variables, and to see the effect of applying the natural log transformation to the `Serum_Insulin` variable. A dashed red line showing a true normal distribution will also appear in the figure as a basis of comparison.\n","\n","Note that the transformation applied to the `Pregnancies` variable is  $log(x + 1)$. This is because many of the women in the dataset have zero pregnancies, and  $log(0)$ is undefined."]},{"cell_type":"code","metadata":{"trusted":true,"id":"rkJCMeb3aBFg"},"source":["#apply natural log transformations to skewed variables\n","df['Pregnancies'] = [math.log(x + 1) for x in df['Pregnancies']]\n","serum_insulin_original = df['Serum_Insulin'].copy() #save a copy of the original (untransformed) serum insulin levels\n","df['Serum_Insulin'] = [math.log(x) for x in df['Serum_Insulin']]\n","df['BMI'] = [math.log(x) for x in df['BMI']]\n","df['Diabetes_Pedigree'] = [math.log(x) for x in df['Diabetes_Pedigree']]\n","df['Age'] = [math.log(x) for x in df['Age']]\n","\n","#get values for plotting a normal distribution for the transformed \"Serum_Insulin\" variable\n","mean, std = df.Serum_Insulin.mean(), df.Serum_Insulin.std()\n","x = np.arange(mean - (3 * std), mean + (3 * std), std / 10)\n","\n","#plot the untransformed and transformed distributions for the \"Serum_Insulin\" variable\n","fig, ax = plt.subplots(1, 2, figsize=(8,4))\n","sns.kdeplot(serum_insulin_original, ax=ax[0], fill=True, lw=2)\n","sns.lineplot(x=x, y=norm.pdf(x, mean, std), ax=ax[1], lw=2, color='r', linestyle='--')\n","sns.kdeplot(df.Serum_Insulin, ax=ax[1], fill=True, lw=2)\n","ax[0].title.set_text('Original')\n","ax[1].title.set_text('After Natural Log Transformation')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rSeVVflVaBFh"},"source":["As you can see, the natural log transformation made the shape of the distribution for the `Serum_Insulin` variable much more normal.\n","### Rescaling Predictor Variables\n","A key objective in this lab is to train a machine learning model to accurately predict whether a woman has diabetes. For our dataset, this means that `Has_Diabetes` is the outcome variable. In machine learning, outcome variables are often referred to as *labels*. All of the other variables in our dataset will serve as predictors; i.e., the machine learning models will try to learn to predict if a woman has diabetes based on the values of these predictor variables. In machine learning, predictor variables are often referred to as *features*.\n","\n","Our next data preparation task is to rescale all of our features. In this case, we will use a min-max scaler to rescale the values of each feature / predictor variable to the range 0 to 1.\n","\n","***Why should we rescale our numeric features?*** Because many machine learning algorithms are sensitive to different ranges of values among predictor variables! Variables that contain large values, for example, might be given more weight or influence by the machine learning algorithm during the training process. We can avoid this problem by ensuring that all of the features use the same scale.\n","\n","Run the code cell below to rescale all of the predictor variables to a range of 0 to 1."]},{"cell_type":"code","metadata":{"trusted":true,"id":"Hd9pE7yhaBFi"},"source":["#define a min-max scaler and rescale all predictor variables to the range 0 to 1\n","scaler = MinMaxScaler(feature_range=(0,1))\n","predictors = ['Pregnancies', 'Plasma_Glucose', 'Diastolic_Blood_Pressure', 'Triceps_Thickness', 'Serum_Insulin', 'BMI', 'Diabetes_Pedigree', 'Age']\n","df[predictors] = scaler.fit_transform(df[predictors])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ir1cwPFGaBFj"},"source":["#### Task 06:\n","Write a line of code in the cell below that will display descriptive statistics for all of the rescaled predictor variables in the dataframe.\n","\n","Note that all of the features now have a minimum of 0.0 and a maximum of 1.0.\n","#### Question 06:\n","What is the median of the rescaled `Plasma_Glucose` variable? Report three decimals of precision (e.g., 0.123).\n","\n","Just in case you've forgotten, *2nd quartile* and *50th percentile* are other names for the median!"]},{"cell_type":"code","metadata":{"trusted":true,"id":"dkIUwSPzaBFj"},"source":["#show descriptive statistics for all of the rescaled predictor variables.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uVJoPSRaBFj"},"source":["### Split the Data into Training and Testing Sets\n","Our final data preparation task is to split our data into training and testing sets. The basic idea is that we want to use the training data to teach the machine learning models to predict whether a woman has diabetes. We can then evaluate how well those models are likely to work in the real world by testing how accurate their predictions are *for women they haven't seen before* (i.e., for the women in the testing set).\n","\n","***The difference between how accurate the machine learning model's predictions are on the training vs. testing sets will tell us something very important:***\n","* Ideally, we want the predictive accuracy to be high for both the training and testing sets -- this indicates that the machine learning model has accurately learned to solve the underlying problem.\n","* If there is a large difference between how well the model works for the training vs. testing data, then it is likely that the model is *overfitted* to the training data -- this indicates that the machine learning algorithm has focused too specifically on the training data that it was given, and has not identified a more general solution to the underlying problem. For more information about this phenomenon, please feel free to read [this article on overfitting](https://en.wikipedia.org/wiki/Overfitting).\n","\n","Run the code cell below to split the diabetes data into separate training and testing sets. The training data will be stored in a dataframe named `df_train`, while the testing data will be stored in a dataframe named `df_test`."]},{"cell_type":"code","metadata":{"trusted":true,"id":"w_W7r76waBFk"},"source":["#split the data into training and testing sets\n","df_train, df_test = train_test_split(df.copy(), train_size=0.7, shuffle=True, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y6RUlztEaBFk"},"source":["#### Task 07:\n","Write two lines of code that will tell you (1) how many rows of data are in the training dataframe, and (2) how many rows of data are in the testing dataframe.\n","#### Question 07:\n","How many rows of data are in the testing set?"]},{"cell_type":"code","metadata":{"trusted":true,"id":"ncnoeJHAaBFk"},"source":["#display the number of rows in the training set\n","\n","\n","#display the number of rows in the testing set\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GsIxizzcaBFl"},"source":["## Train and Test the Machine Learning Models\n","Now that our data have been fully prepared, we're finally ready to train and test a few machine learning models!\n","### Logistic Regression Classifier\n","The first machine learning model that we'll build is a *logistic regression classifier*. This type of model relies on the ubiquitous regression framework to predict the probability of a woman having diabetes.\n","\n","You may learn more about logistic regression by [reading this article](https://en.wikipedia.org/wiki/Logistic_regression).\n","\n","Run the code cell below to train a logistic regression classifier. Note that the model is being trained with our training set."]},{"cell_type":"code","metadata":{"trusted":true,"id":"lPMeBPa5aBFl"},"source":["#train a logistic regression classifier\n","model = LogisticRegression(random_state=42)\n","model.fit(df_train[predictors], df_train.Has_Diabetes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VRs-wnuVaBFm"},"source":["Now that our logistic regression classifier has been trained, it's time to evaluate how well it performs using our testing set.\n","\n","Run the code cell below to generate and view the model's predictions about whether the women in the testing set have diabetes."]},{"cell_type":"code","metadata":{"trusted":true,"id":"eGL72eJPaBFm"},"source":["#generate predictions, and save them in a new column named \"Has_Diabetes_Predicted\" in the testing dataframe\n","df_test['Has_Diabetes_Predicted'] = model.predict(df_test[predictors])\n","\n","#view actual and predicted values for the first 20 women in the testing set\n","df_test[['Has_Diabetes', 'Has_Diabetes_Predicted']].head(20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D9Lg4j7PaBFm"},"source":["As you can see, the logistic regression classifier is able to accurately predict whether most of the women in the testing set have diabetes or not, but it does make a few mistakes.\n","\n","Let's take a closer look at how well our logistic regression classifier performs. The most common way to evaluate the performance of a classifier is to use a **confusion matrix**. A confusion matrix displays the number of correctly and incorrectly classified cases in a table, as shown below:\n","\n","| | Predicted Negative | Predicted Positive |  \n","|------|:------:|:------:| \n","|**Actual Negative**| True Negative | False Positive (Type I error) |  \n","|**Actual Positive** | False Negative (Type II error) | True Positive |\n","\n","Here the four elements in the matrix are defined as:    \n","**True Positive** or **TP** are cases with positive labels (*1s*) that have been correctly classified as positive.     \n","**True Negative** or **TN** are cases with negative labels (*0s*) that have been correctly classified as negative.  \n","**False Positive** or **FP** are cases with negative labels that have been incorrectly classified as positive.   \n","**False Negative** or **FN** are cases with positive labels that have been incorrectly classified as negative.\n","\n","Additional performance metrice include:\n","\n","**Accuracy**: Accuracy is the percentage of all cases that were correctly predicted.\n","\n","**Precision**: Precision is the number of correctly predicted cases for the label value divided by all of the cases in the column.\n","\n","**Recall**: Recall is the percentage of cases of a label value that were correctly predicted out of all cases that actually have that label value.\n","\n","**F1**: The F1 statistic is weighted average of precision and recall. Put differently, F1 is a weighted metric for overall model performance.\n","#### Task 08:\n","Run the code cell below to view a confusion matrix and other performance metrics for our logistic regression classifier.\n","#### Question 08:\n","What is the overall accuracy for the logistic regression classifier? Report three decimals of precision (e.g., 0.876)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"byKat90faBFn"},"source":["#define a function that prints a confusion matrix and other performance metrics\n","def print_metrics(actual, predicted):\n","  tn, fp, fn, tp = confusion_matrix(actual, predicted).ravel()\n","  total_predictions = tn + fp + fn + tp\n","  print(' True positive: {} ({:.2f}%)'.format(tp, tp / total_predictions * 100))\n","  print(' True negative: {} ({:.2f}%)'.format(tn, tn / total_predictions * 100))\n","  print('False positive: {} ({:.2f}%)'.format(fp, fp / total_predictions * 100))\n","  print('False negative: {} ({:.2f}%)\\n'.format(fn, fn / total_predictions * 100))\n","  target_names=['does not have diabetes', 'has diabetes']\n","  print(classification_report(actual, predicted, target_names=target_names, digits=4))\n","\n","#show the performance of the model on the testing data\n","print_metrics(df_test.Has_Diabetes, df_test.Has_Diabetes_Predicted)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zLy58Ax1aBFn"},"source":["Although the logistic regression classifier is reasonably accurate overall, the values shown in the confusion matrix are troubling. Specifically, the false positive rate and particularly the false negative rate are quite large. \n","\n","***Think about what this means in the context of a disease prediction scenario.***\n","* In our scenario, a **false positive** could lead a doctor to tell a patient that she has diabetes when she actually does not. This is obviously a bad situation. Not only will the patient suffer needless psychological stress, but she may also be subjected to additional unnecessary tests or required to take unnecessary medications.\n","* A **false negative** in our scenario, however, would be *really, really bad* because it might lead a doctor to tell a patient that she does not have diabetes when she actually does have the disease. This could be life threatening! The recall metric shows that only about 67% of the women who actually have diabetes were correctly labeled as having diabetes. **This means that about 33% of the women who actually have diabetes were incorrectly labeled as not having diabetes.** Given how dangerous this could be, our logistic regression classifier is obviously not well-suited for real-world use.\n","\n","### ROC Curves\n","A very useful graphical technique for evaluating the performance of a machine learning classifier model is to generate a receiver operating characteristic (ROC) curve. A ROC curve shows the relationship between a model's true positive rate and its false positive rate. Consider that when our model predicts that a woman has diabetes, the prediction is either correct (true positive) or incorrect (false positive). Therefore:\n","* The best performing classifier model is the one with the highest true positive rate and the lowest false positive rate. ROC curves for models with these characteristics approach very closely to the upper-left corner of the diagram.\n","* Models that have a poor ratio of true positive predictions to false positive predictions will have ROC curves that are closer to an upward slanting line that extends from the lower-left of the diagram to the upper-right of the diagram.\n","* Thus, as the performance of a model improves, the area under the curve (AUC) increases. As such, the area under the ROC curve is an excellent measure of the usefulness of a machine learning classifier model in general, where a greater area indicates a more useful model. ***Comparing the AUCs of different models is therefore an excellent way of deciding which classifier model is best!***\n","\n","#### Task 09:\n","Run the code cell below to generate a ROC curve for our linear regression classifier.\n","#### Question 09:\n","What is the area under the ROC curve for the logistic regression classifier? Report three decimals of precision (e.g., 0.789)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"FDwdJBnZaBFo"},"source":["#define a function that generates a ROC curve\n","def generate_roc_curve(actual, predicted_probabilities):\n","  fpr, tpr, _ = roc_curve(actual, predicted_probabilities)\n","  auc = roc_auc_score(actual, predicted_probabilities)\n","  plt.plot(fpr, tpr, 'b-', lw=2, label='Area Under Curve (AUC): {0:.3f}'.format(auc))\n","  plt.plot([0, 1], [0, 1], 'r--')\n","  plt.title('ROC Curve')\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.legend(loc=4)\n","  plt.show()\n","\n","#compute predicted probabilities that each woman in the testing set has diabetes\n","predicted_probabilities = model.predict_proba(df_test[predictors])[::,1]\n","\n","#generate a ROC curve for the logistic regression classifier\n","generate_roc_curve(df_test.Has_Diabetes, predicted_probabilities)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wdPH6LluaBFo"},"source":["The blue line in the diagram shows the trade-off between the true positive rate and the false positive rate for the logistic regression classfier, while the dashed red line represents a hypothetical \"unskilled\" model that has learned nothing from the data. Ideally, we want our models to have a very high true positive rate and a very low false positive rate. This means that the closer the ROC curve (i.e., the blue line) is to the upper-left corner of the diagram, the better the model is, and the larger the area under the curve (AUC) will be. Comparing the AUCs for ROC curves from two or more classifier models can therefore help us to identify the superior model.\n","### K-Nearest Neighbors (KNN) Classifier\n","Since our logistic regression classifier has some problems, let's see if we can acheive better results by using a k-nearest neighbors (KNN) classifier. This type of classifier uses a simple majority voting approach in which each unknown case is classified based on the categories of the *k* nearest known cases.\n","\n","To learn more about how KNN classification works, please [read this article](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).\n","#### Task 10:\n","Run the code cell below to train our KNN classifier and view its resulting confusion matrix and other performance metrics.\n","#### Question 10:\n","What is the overall accuracy for the KNN classifier? Report three decimals of precision (e.g., 0.852)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"73AzY3AeaBFo"},"source":["#train a k-nearest neighbors (KNN) classifier\n","model = KNeighborsClassifier(n_neighbors=11)\n","model.fit(df_train[predictors], df_train.Has_Diabetes)\n","\n","#evaluate the performance of the KNN classifier using the test set\n","df_test['Has_Diabetes_Predicted'] = model.predict(df_test[predictors])\n","\n","#show the performance of the model on the testing data\n","print_metrics(df_test.Has_Diabetes, df_test.Has_Diabetes_Predicted)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H2x0jbnJaBFp"},"source":["The KNN classifier is more accurate than our logistic regression classifier. Among women who actually have diabetes, the KNN classifier also has a much lower false negative rate of about 18% (compared to a false negative rate of about 33% with the logistic regression classifier).\n","\n","Now let's take a look at the ROC curve for the KNN classifier.\n","#### Task 11:\n","Run the code cell below to generate a ROC curve for our KNN classifier.\n","#### Question 11:\n","What is the area under the ROC curve for the KNN classifier? Report three decimals of precision (e.g., 0.987)."]},{"cell_type":"code","metadata":{"trusted":true,"id":"M1uodnupaBFp"},"source":["#compute predicted probabilities that each woman in the testing set has diabetes\n","predicted_probabilities = model.predict_proba(df_test[predictors])[::,1]\n","\n","#generate a ROC curve for the KNN classifier\n","generate_roc_curve(df_test.Has_Diabetes, predicted_probabilities)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDLOWOS3aBFp"},"source":["As you can see, the ROC curve for the k-nearest neighbors classifier is much closer to the upper-left corner of the diagram than the logistic regression classifier, and the area under the KNN classifier's ROC curve is also larger that that of the logistic regression classifier. We can therefore conclude that the KNN classifier is substantially better at predicting whether a woman has diabetes than the logistic regression model, at least among women who belong to the Pima people."]},{"cell_type":"markdown","metadata":{"trusted":true,"id":"MPu2AXNyaBFq"},"source":["### Know Your Performance Baseline!\n","Finally, it is always important to know the appropriate baseline against which to compare your model's performance. The descriptive statistics that we generated at the beginning of this lab show that exactly one-third (33.333%) of the women in the dataset actually have diabetes. ***This means that without doing anything, we could simply guess that a woman in the dataset does not have diabetes, and we would be correct 66.667% of the time.*** The correct performance baseline for this scenario is thus 66.667% -- any machine learning model whose predictive accuracy is at or below this threshold is basically worthless!"]},{"cell_type":"markdown","metadata":{"id":"4jGAotWu6eH6"},"source":["## End of Lab Assignment 01!"]}]}